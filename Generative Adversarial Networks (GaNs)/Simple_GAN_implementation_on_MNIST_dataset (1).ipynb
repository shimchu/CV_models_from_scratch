{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing Libraries"
      ],
      "metadata": {
        "id": "h7DCnJJ84JCR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNdyEKu30y2h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.tensorboard import SummaryWriter # to print to tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Coding the model"
      ],
      "metadata": {
        "id": "rHLmnaWu4vAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Generator And Discriminator:\n"
      ],
      "metadata": {
        "id": "pbs2Xoi040Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 28\n",
        "channels = 1\n",
        "img_shape = (channels, img_size, img_size)"
      ],
      "metadata": {
        "id": "OVZi3wg28Rli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (1, 28, 28)"
      ],
      "metadata": {
        "id": "0rd7FxQPRToe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, latent_dim,img_shape):    #latent_dim = z_dim\n",
        "    super().__init__()\n",
        "\n",
        "    def layer_block(input_size, output_size, normalize = True):\n",
        "      layers = [nn.Linear(input_size, output_size)]\n",
        "      if normalize:\n",
        "        layers.append(nn.BatchNorm1d(output_size, 0.8))\n",
        "      layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
        "      return layers\n",
        "\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        *layer_block(latent_dim, 128, normalize = False),\n",
        "        *layer_block(128,256),\n",
        "        nn.Linear(256,int(np.prod(img_shape))),\n",
        "        nn.Tanh()\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    img = self.model(z)\n",
        "    img = img.view(img.size(0), *img_shape)\n",
        "    return img\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.img_shape = img_shape\n",
        "    self.flattened_size = int(np.prod(self.img_shape))\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.flattened_size, 512),   # (int(np.prod(img_shape) meaning?\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "        nn.Linear(256,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,img):\n",
        "    img_flat = img.view(img.size(0), -1)\n",
        "    verdict = self.model(img_flat)\n",
        "    return verdict\n"
      ],
      "metadata": {
        "id": "HCuyXTUv45pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#creating instances\n",
        "generator = Generator(latent_dim = 128, img_shape = (1,28,28)).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "adv_loss = torch.nn.BCELoss().to(device)\n"
      ],
      "metadata": {
        "id": "ihgy663z-kY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Getting datasets"
      ],
      "metadata": {
        "id": "OHnAEIEp_e8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "os.makedirs('data/mnist', exist_ok = True)\n",
        "dataloader = DataLoader(datasets.MNIST('data/mnist', train = True, download = True,\n",
        "                                       transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                                                       transforms.Normalize((0.5,),(0.5,))]\n",
        "                                                                      )),\n",
        "                        batch_size = batch_size, shuffle = True\n",
        "                        )"
      ],
      "metadata": {
        "id": "W3vdv54F_jrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Training GAN:"
      ],
      "metadata": {
        "id": "fM9o1YBcA8D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 3e-4\n",
        "latent_dim = 128 # 64, 128, 256\n",
        "batchSize = 32  # Batch size\n",
        "epochs = 200  # Change as per your need\n",
        "logStep = 625  # Change as per your need"
      ],
      "metadata": {
        "id": "GzmXWBD3NYqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('output_dir/images', exist_ok = True)"
      ],
      "metadata": {
        "id": "qxbOHyOBGylW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim_G = torch.optim.Adam(generator.parameters(), lr = lr)\n",
        "optim_D = torch.optim.Adam(discriminator.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "PgzkbeQ2A0Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixedNoise = torch.randn((batch_size,\n",
        "                              latent_dim)).to(device)\n",
        "\n",
        "writerFake = SummaryWriter(f\"logs/fake\")\n",
        "writerReal = SummaryWriter(f\"logs/real\")\n",
        "def prepareVisualisation(epochs,i,loaderlen,lossD, lossG, writerFake, writerReal, step):\n",
        "  with torch.no_grad():\n",
        "    fake = generator(fixedNoise.reshape(-1,1,28,28))\n",
        "    data = real.reshape(-1,1,28,28)\n",
        "\n",
        "    imgGridFake = torchvision.utils.make_grid(fake, normalize = True)\n",
        "    imgGridReal = torchvision.utlis.make_grid(data, normalize = True)\n",
        "    writerFake.add_image(\"Mnist Fake Images\",\n",
        "                            imgGridFake,\n",
        "                            global_step=step)\n",
        "    writerReal.add_image(\"Mnist Real Images\",\n",
        "                          imgGridReal,\n",
        "                          global_step=step)\n",
        "    # increment step\n",
        "    step += 1\n",
        "    return step\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "chMXnJw1JLQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "step = 0\n",
        "images_for_gif = []\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  for i, (real, _)in enumerate(dataloader):   # no model.train()?\n",
        "    real = real.view(-1, 784).to(device)\n",
        "\n",
        "  ## Training discrimibator:\n",
        "    noise = torch.randn(batch_size,latent_dim).to(device)\n",
        "    fake = generator(noise)\n",
        "    discReal = discriminator(real).view(-1)\n",
        "    lossDreal = adv_loss(discReal, torch.ones_like(discReal))\n",
        "    discFake = discriminator(fake).view(-1)\n",
        "    lossDfake = adv_loss(discFake, torch.zeros_like(discFake))\n",
        "\n",
        "    lossD = (lossDreal + lossDfake) / 2\n",
        "    discriminator.zero_grad()\n",
        "    lossD.backward(retain_graph=True)\n",
        "    optim_D.step()\n",
        "\n",
        "    ### Training Generator\n",
        "    output = discriminator(fake).view(-1)\n",
        "    lossG = adv_loss(output, torch.ones_like(output))\n",
        "    generator.zero_grad()\n",
        "    lossG.backward()\n",
        "    optim_G.step()\n",
        "  print(\n",
        "      f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(dataloader)} \\\n",
        "                            Loss DISC: {lossD:.4f}, loss GEN: {lossG:.4f}\"\n",
        "  )\n",
        "\n",
        "  losses.append((lossG.item(),lossD.item()))g\n",
        "  image_filename = f'output_dir/images/{epoch}.png'\n",
        "  save_image(fake.data[:25], image_filename, nrow = 5, normalize = True)\n",
        "  images_for_gif.append(imageio.imread(image_filename))\n",
        "\n",
        "\n",
        "imageio.mimwrite(f'output_dir/genimage.gif', images_for_gif, fps = len(fake)/5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjs3GXk6B2nM",
        "outputId": "f420c151-4a98-412c-a23b-abbbfe1f539d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/5] Batch 1874/1875                             Loss DISC: 0.2194, loss GEN: 3.1103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-dc4a2a72d4dc>:36: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  images_for_gif.append(imageio.imread(image_filename))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] Batch 1874/1875                             Loss DISC: 0.2035, loss GEN: 3.1787\n",
            "Epoch [2/5] Batch 1874/1875                             Loss DISC: 0.1654, loss GEN: 4.0779\n",
            "Epoch [3/5] Batch 1874/1875                             Loss DISC: 0.4142, loss GEN: 2.3229\n",
            "Epoch [4/5] Batch 1874/1875                             Loss DISC: 0.2253, loss GEN: 2.9356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources:\n",
        "\n",
        "\n",
        "Code:\n",
        "https://www.baeldung.com/cs/pytorch-generative-adversarial-networks#:~:text=In%20this%20article%2C%20we%20showed,but%20are%20challenging%20to%20train.\n",
        "\n",
        "Theory: +code\n",
        "\n",
        "https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
        "\n",
        "https://github.com/vamsi3/simple-GAN/blob/master/src/PyTorch/gan-mnist-pytorch.py\n",
        "\n",
        "\n",
        "https://medium.com/@wasuratme96/building-a-simple-gan-model-9bfea22c651f\n",
        "\n",
        "\n",
        "YT:\n",
        "GAN explanation:\n",
        "\n",
        "https://youtu.be/OXWvrRLzEaU?si=s7mw0UYlhrKvIiYR\n",
        "\n",
        "Simple GAN explanation:\n",
        "\n",
        "https://youtu.be/OXWvrRLzEaU?si=s7mw0UYlhrKvIiYR\n"
      ],
      "metadata": {
        "id": "YSTFHMtciiz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Try:\n",
        "1. increasing size of Gen and discrim\n",
        "2. increasing number of epochs to 200"
      ],
      "metadata": {
        "id": "e7xn7ozskCBc"
      }
    }
  ]
}